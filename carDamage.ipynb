{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b570f4-092b-4fe6-810b-2a4820082d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\user\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: keras in c:\\users\\user\\anaconda3\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras) (0.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas matplotlib seaborn opencv-python scikit-learn tensorflow keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35eea748-8700-418f-a1f8-5351e63521c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\user\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: keras in c:\\users\\user\\anaconda3\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras) (0.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python tensorflow keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "993b9c84-0335-4724-918d-34e15283ab9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloads/data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[1;32m----> 7\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image)\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample Image\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "image_path = \"Downloads/data.csv\"\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.title(\"Sample Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce5112b7-341e-4b61-ae2a-d42d8a1f52cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>image/0.jpeg</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>image/1.jpeg</td>\n",
       "      <td>head_lamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>image/2.jpeg</td>\n",
       "      <td>door_scratch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>image/3.jpeg</td>\n",
       "      <td>head_lamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>image/4.jpeg</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         image       classes\n",
       "0           0  image/0.jpeg       unknown\n",
       "1           1  image/1.jpeg     head_lamp\n",
       "2           2  image/2.jpeg  door_scratch\n",
       "3           3  image/3.jpeg     head_lamp\n",
       "4           4  image/4.jpeg       unknown"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Downloads/data.csv\")\n",
    "data.head()  # Show first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4fd45fd-6e86-4566-95ec-a1033068c2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>image/0.jpeg</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>image/1.jpeg</td>\n",
       "      <td>head_lamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>image/2.jpeg</td>\n",
       "      <td>door_scratch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>image/3.jpeg</td>\n",
       "      <td>head_lamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>image/4.jpeg</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         image       classes\n",
       "0           0  image/0.jpeg       unknown\n",
       "1           1  image/1.jpeg     head_lamp\n",
       "2           2  image/2.jpeg  door_scratch\n",
       "3           3  image/3.jpeg     head_lamp\n",
       "4           4  image/4.jpeg       unknown"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"Downloads/data.csv\")\n",
    "\n",
    "# Preview the data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96e91533-867a-4e7f-937e-c4f7d4baca0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1594 entries, 0 to 1593\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  1594 non-null   int64 \n",
      " 1   image       1594 non-null   object\n",
      " 2   classes     1594 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 37.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "image         0\n",
       "classes       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3d763c2-ad59-4a76-b26c-3c32a364a005",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m      3\u001b[0m encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m----> 4\u001b[0m y \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mfit_transform(y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)  # Convert classes to 0, 1, 2...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9389a7c0-1c7c-4fcf-824b-2b644535e490",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['damage_type'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdamage_type\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdamage_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5582\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5583\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5584\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5585\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5586\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5587\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5588\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5589\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['damage_type'] not found in axis\""
     ]
    }
   ],
   "source": [
    "X = df.drop('damage_type', axis=1)\n",
    "y = df['damage_type']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25638407-1e15-499c-8ed7-5f9833e35286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'image', 'classes'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e08d4275-5cab-4181-83a4-83f9654006f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classes\n",
       "unknown           549\n",
       "door_dent         192\n",
       "bumper_scratch    164\n",
       "door_scratch      154\n",
       "glass_shatter     137\n",
       "tail_lamp         136\n",
       "head_lamp         133\n",
       "bumper_dent       129\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df['classes'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e744d85-b517-4eac-a89b-0bb8ffbee6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13b11ffc-eb6e-46e4-b310-be85fbe8e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['classes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "400a7a07-e4a7-4478-aa22-3e05933b3212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edbf80b7-f76d-4ba1-a68c-5ea907c1172e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "base_model = MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3b21722-3707-41d3-8450-b43bc5cca37a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      2\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Use 'sparse_categorical_crossentropy' if labels are integers\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',  # Use 'sparse_categorical_crossentropy' if labels are integers\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6518df02-2c03-4363-aa46-a02758ec9f7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 12\u001b[0m\n\u001b[0;32m      4\u001b[0m base_model\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# Freeze base model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Add classification head\u001b[39;00m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m      8\u001b[0m     base_model,\n\u001b[0;32m      9\u001b[0m     layers\u001b[38;5;241m.\u001b[39mGlobalAveragePooling2D(),\n\u001b[0;32m     10\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     11\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.3\u001b[39m),\n\u001b[1;32m---> 12\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# replace `num_classes` with the number of damage types\u001b[39;00m\n\u001b[0;32m     13\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_classes' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  # Freeze base model\n",
    "\n",
    "# Add classification head\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(num_classes, activation='softmax')  # replace `num_classes` with the number of damage types\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a620b424-0bde-42cc-850f-ef72ffa8699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = df['classes'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b96c8f7-793e-4cec-bd95-c5232bb95709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Count number of unique classes\n",
    "num_classes = df['classes'].nunique()\n",
    "\n",
    "# Load base model\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build the model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "491b7f94-476b-4832-bb7f-ae2be9bd3aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd3ef7d7-5b81-4f59-a218-e47722fd60ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m----> 2\u001b[0m     train_generator,\n\u001b[0;32m      3\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m      4\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_generator,\n\u001b[0;32m      5\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stopping, reduce_lr]\n\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ec47374-c746-4b4d-a789-cb796848e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20216ecd-4b04-4392-b0a4-b0bb2e260b77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Acc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Acc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.legend()\n",
    "plt.title('Accuracy over epochs')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss over epochs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab2a9dcb-5d4b-4091-ba3e-45926fa37ffe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m----> 2\u001b[0m     train_generator,\n\u001b[0;32m      3\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      4\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_generator\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60422adb-3b34-4b73-aded-842a13c63f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:920: UserWarning: Found 1594 invalid image filename(s) in x_col=\"image\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:920: UserWarning: Found 1594 invalid image filename(s) in x_col=\"image\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Step 1: Load the CSV\n",
    "df = pd.read_csv(r'C:/Users/USER/Downloads/archive (3)/data.csv')\n",
    "\n",
    "# Step 2: Set full image path in dataframe\n",
    "df['image'] = df['image'].apply(lambda x: f\"C:/Users/USER/Downloads/archive (3)/image/{x}\")\n",
    "\n",
    "# Step 3: ImageDataGenerator\n",
    "datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    x_col='image',\n",
    "    y_col='classes',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    x_col='image',\n",
    "    y_col='classes',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ed91b509-703c-45f2-b8e2-9b7cc2427cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# base directory\n",
    "image_dir = r'C:/Users/USER/Downloads/archive (3)/image'\n",
    "\n",
    "# prepend image path\n",
    "df['image'] = df['image'].apply(lambda x: os.path.join(image_dir, x.strip()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8495045-97df-4049-876c-cf2e1f3e379b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:920: UserWarning: Found 1594 invalid image filename(s) in x_col=\"image\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    x_col='image',\n",
    "    y_col='classes',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "badf370e-b7fd-4f97-905a-8a58df151b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files: 1594\n",
      "0    C:/Users/USER/Downloads/archive (3)/image/imag...\n",
      "1    C:/Users/USER/Downloads/archive (3)/image/imag...\n",
      "2    C:/Users/USER/Downloads/archive (3)/image/imag...\n",
      "3    C:/Users/USER/Downloads/archive (3)/image/imag...\n",
      "4    C:/Users/USER/Downloads/archive (3)/image/imag...\n",
      "Name: image, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "missing = df[~df['image'].apply(os.path.exists)]\n",
    "print(f\"Missing files: {len(missing)}\")\n",
    "print(missing['image'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5466eb28-9d0f-4c48-9206-3048fd25c349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:920: UserWarning: Found 1594 invalid image filename(s) in x_col=\"image\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    x_col='image',\n",
    "    y_col='classes',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5a77f3b5-00c5-4cf1-a2f4-b647f4feaafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    C:/Users/USER/Downloads/archive (3)/image/imag...\n",
       "1    C:/Users/USER/Downloads/archive (3)/image/imag...\n",
       "2    C:/Users/USER/Downloads/archive (3)/image/imag...\n",
       "3    C:/Users/USER/Downloads/archive (3)/image/imag...\n",
       "4    C:/Users/USER/Downloads/archive (3)/image/imag...\n",
       "Name: image, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "92de2232-e0f8-4ffd-a5bc-8a256479d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Folder where the images are\n",
    "image_folder = r'C:/Users/USER/Downloads/archive (3)/image'\n",
    "\n",
    "# Only use the filename (no 'image/' inside)\n",
    "df['image'] = df['image'].apply(lambda x: os.path.join(image_folder, os.path.basename(str(x).strip())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f32ac05c-dc35-4365-b334-61cfb097afd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1276 validated image filenames belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    x_col='image',\n",
    "    y_col='classes',  # make sure this column exists in your CSV\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "10a0c05d-5cb4-4ce2-929c-6bbbbc5d0590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f58e82d-8e00-4647-a08b-bf0b043fc869",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameIterator' object has no attribute 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get number of classes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m train_generator\u001b[38;5;241m.\u001b[39mnum_classes\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load base model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m base_model \u001b[38;5;241m=\u001b[39m MobileNetV2(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m), include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrameIterator' object has no attribute 'num_classes'"
     ]
    }
   ],
   "source": [
    "# Get number of classes\n",
    "num_classes = train_generator.num_classes\n",
    "\n",
    "# Load base model\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  # freeze base\n",
    "\n",
    "# Add custom layers\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "53d56b8c-80a4-400a-8e19-9f1d8a0a2fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3d2e549c-058f-4c1f-9532-9b1a84ccd379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "38425f41-8070-473a-8cad-20147a0b2f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e28b4171-c6f1-4e67-b952-3827658ba245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 318 validated image filenames belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    x_col='image',\n",
    "    y_col='classes',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a0010e50-c85b-4da6-b2d4-089c034976c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 981ms/step - accuracy: 0.4377 - loss: 1.7382 - val_accuracy: 0.6918 - val_loss: 0.9328\n",
      "Epoch 2/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 661ms/step - accuracy: 0.7176 - loss: 0.8039 - val_accuracy: 0.7893 - val_loss: 0.6747\n",
      "Epoch 3/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 726ms/step - accuracy: 0.8153 - loss: 0.5520 - val_accuracy: 0.8208 - val_loss: 0.6089\n",
      "Epoch 4/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 679ms/step - accuracy: 0.8511 - loss: 0.4879 - val_accuracy: 0.7893 - val_loss: 0.5861\n",
      "Epoch 5/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 672ms/step - accuracy: 0.8814 - loss: 0.3311 - val_accuracy: 0.8208 - val_loss: 0.5634\n",
      "Epoch 6/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 695ms/step - accuracy: 0.9025 - loss: 0.3039 - val_accuracy: 0.8239 - val_loss: 0.5324\n",
      "Epoch 7/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 680ms/step - accuracy: 0.9399 - loss: 0.2248 - val_accuracy: 0.8239 - val_loss: 0.5333\n",
      "Epoch 8/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 682ms/step - accuracy: 0.9661 - loss: 0.1622 - val_accuracy: 0.8208 - val_loss: 0.5290\n",
      "Epoch 9/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 680ms/step - accuracy: 0.9558 - loss: 0.1592 - val_accuracy: 0.8302 - val_loss: 0.5687\n",
      "Epoch 10/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 749ms/step - accuracy: 0.9670 - loss: 0.1374 - val_accuracy: 0.8239 - val_loss: 0.5491\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fdf0b177-0c60-4703-bd9b-c85a686aa628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "605106c1-d9c0-4aaf-b06d-8a52c364aad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('car_damage_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "235c1cf1-ac80-4f79-a426-cac38bf361ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mflow_from_dataframe(\n\u001b[0;32m      2\u001b[0m     dataframe\u001b[38;5;241m=\u001b[39mtrain_df,\n\u001b[0;32m      3\u001b[0m     directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m      4\u001b[0m     x_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m     y_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m),\n\u001b[0;32m      7\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m      9\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datagen' is not defined"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=None,\n",
    "    x_col='image',\n",
    "    y_col='classes',\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4461b68b-ba16-49a0-8993-40465562c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the data generator\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1577f723-3e92-442a-acb7-083f1f393cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV from current working directory\n",
    "df = pd.read_csv(\"data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a2d731b-9ab9-4639-b087-b3838248c597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1276 validated image filenames belonging to 8 classes.\n",
      "Found 318 validated image filenames belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=None,\n",
    "    x_col='image',\n",
    "    y_col='classes',\n",
    "    subset='training',\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=None,\n",
    "    x_col='image',\n",
    "    y_col='classes',\n",
    "    subset='validation',\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "940c2f19-2536-494c-be7c-0de842afb66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bumper_dent': 0, 'bumper_scratch': 1, 'door_dent': 2, 'door_scratch': 3, 'glass_shatter': 4, 'head_lamp': 5, 'tail_lamp': 6, 'unknown': 7}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "169c8ba8-f4a1-4cac-a929-2c32c1c47a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bumper_dent': 0, 'bumper_scratch': 1, 'door_dent': 2, 'door_scratch': 3, 'glass_shatter': 4, 'head_lamp': 5, 'tail_lamp': 6, 'unknown': 7}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7535918-2c38-46bf-8fe6-338ba8434079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to get the correct class order\n",
    "class_indices = train_generator.class_indices\n",
    "\n",
    "# Sort by the index to get correct order\n",
    "class_names = [cls for cls, idx in sorted(class_indices.items(), key=lambda x: x[1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed0f255-1dae-414e-9b1c-3a720801b56e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
